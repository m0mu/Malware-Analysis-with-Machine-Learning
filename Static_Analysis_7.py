
# coding: utf-8

# In[ ]:


# For Presentation - Just Decision Tree


# In[2]:


import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_oemid"] = pe.DOS_HEADER.e_oemid
        attr_dict["e_oeminfo"] = pe.DOS_HEADER.e_oeminfo       
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["Machine"] = pe.FILE_HEADER.Machine
        attr_dict["NumberOfSections"] = pe.FILE_HEADER.NumberOfSections       
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        
        attr_dict["MinorLinkerVersion"] = pe.OPTIONAL_HEADER.MinorLinkerVersion
        attr_dict["SizeOfCode"] = pe.OPTIONAL_HEADER.SizeOfCode
        attr_dict["SizeOfInitializedData"] = pe.OPTIONAL_HEADER.SizeOfInitializedData
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["MinorImageVersion"] = pe.OPTIONAL_HEADER.MinorImageVersion
        attr_dict["MajorLinkerVersion"] = pe.OPTIONAL_HEADER.MajorLinkerVersion
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum
        attr_dict["SizeOfHeapReserve"] = pe.OPTIONAL_HEADER.SizeOfHeapReserve
        attr_dict["SizeOfStackCommit"] = pe.OPTIONAL_HEADER.SizeOfStackCommit
        attr_dict["SizeOfStackReserve"] = pe.OPTIONAL_HEADER.SizeOfStackReserve
        attr_dict["DllCharacteristics"] = pe.OPTIONAL_HEADER.DllCharacteristics
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["Reserved1"] = pe.OPTIONAL_HEADER.Reserved1
        attr_dict["SizeOfHeapCommit"] = pe.OPTIONAL_HEADER.SizeOfHeapCommit
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["Subsystem"] = pe.OPTIONAL_HEADER.Subsystem
        attr_dict["MajorSubsystemVerison"] = pe.OPTIONAL_HEADER.MajorSubsystemVersion
        attr_dict["MajorOperatingSystemVersion"] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
        attr_dict["MinorOperatingSystemVersion"] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["ImageBase"] = pe.OPTIONAL_HEADER.ImageBase

    except Exception as e:
        print("")

import hashlib
import sys

def sha256_checksum(filename, path, block_size=65536):
    filename = str(path)+str('/'+filename)
    sha256 = hashlib.sha256()
    with open(filename, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()


# In[ ]:





# In[3]:


# path = '/home/mohit/Desktop/Dynamic_binaries/Benign/0bc8af546901e6c20611c5250bd65acd0c4a8613bd8f8835f0d4680b5777f051'
path2 = '/home/mohit/Desktop/Dynamic_binaries/Benign'

#  getting the names of the files
# pe = pefile.PE(path)
# files = glob.glob(path2)
# for name in files:
list_of_files = (os.listdir(path2))
print(len(list_of_files))
##########################################################################################
# #                           Removing duplicates

temp_list_of_files = []
temp_list_of_files = list_of_files[:]
temp_hashes = []
for file in temp_list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
#         temp_list_of_files.append(file)
    else:
        list_of_files.remove(file)

# print(len(list_of_files))
# print(list_of_files)
############################################################################################

print(len(list_of_benign_dict))


# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
#     pe = pefile.PE(f)
    try:
        pe = pefile.PE(path2+'/'+f)
    except Exception as e:
        print("")
    DOS_HEADER()
#     print("After DOS Header", attr_dict)
    FILE_HEADER()
    OPTIONAL_HEADER()
    
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
# print('BENIGN: \n',list_of_benign_dict)

print(len(list_of_benign_dict))



# In[ ]:





# In[4]:


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

# path3 = '/home/mohit/Desktop/Dynamic_binaries/Malicious/0a143c2e6dabb31a31a6db8cb7a0f77558ae44a38687d5f831c87a98054f0ef9'
path2 = '/home/mohit/Desktop/Dynamic_binaries/Malicious'

# getting the names of the files
# pe = pefile.PE(path3)
# files = glob.glob(path4)
# for name in files:
list_of_files = (os.listdir(path2))
print(len(list_of_files))
##########################################################################################
# #                           Removing duplicates

temp_list_of_files = []
temp_list_of_files = list_of_files[:]
temp_hashes = []
for file in temp_list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
#         temp_list_of_files.append(file)
    else:
        list_of_files.remove(file)

# list_of_files = temp_list_of_files[:]

############################################################################################
    
print(len(list_of_malicious_dict))

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    try:
        pe = pefile.PE(path2+'/'+f)
    except Exception as e:
        print("")
    DOS_HEADER()
    FILE_HEADER()
    OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
# print('\n MALICIOUS: \n', list_of_malicious_dict)
print(len(list_of_malicious_dict))


# In[ ]:





# In[5]:


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

df = df.fillna(0) 
df2 = df2.fillna(0)

print(df)
print(df2)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print('\n \n', to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print('\n \n \n \n \n \n \n \n', final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
import matplotlib.pyplot as plt

# for l in final_list:
#     plt.figure()
#     df4 = pd.DataFrame(l)
#     print(df4)
#     plt.title('HAHAHA it works!')
#     df4.boxplot()
#     plt.show()


# In[ ]:





# In[12]:


X = big_data  # is the merged dataframe of both bengin and malicious files
y = target  # is the classifier column in the big_data


# In[ ]:





# In[28]:



################################################################
#                       Training Model

# path = '/home/mohit/Desktop/Dynamic_binaries/Benign/0bc8af546901e6c20611c5250bd65acd0c4a8613bd8f8835f0d4680b5777f051'
path2 = '/home/mohit/Desktop/Dynamic_binaries/Benign'

# # Benign
# path = '/home/mohit/Desktop/Dynamic_binaries/Benign_all/0bc8af546901e6c20611c5250bd65acd0c4a8613bd8f8835f0d4680b5777f051'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/Benign_all'

# #Malicious
# path = '/home/mohit/Desktop/Dynamic_binaries/Malicious/0a143c2e6dabb31a31a6db8cb7a0f77558ae44a38687d5f831c87a98054f0ef9'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/Malicious'

# Test Both
# path = '/home/mohit/Desktop/Dynamic_binaries/check_benign/0bc8af546901e6c20611c5250bd65acd0c4a8613bd8f8835f0d4680b5777f051'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/check_benign'

# path = '/home/mohit/Desktop/Dynamic_binaries/check_malicious/0bc4586aee6621dfb54fdced45b02cbf087d6e13065b02da3104562b729df634'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/check_malicious'

# path = '/home/mohit/Desktop/Dynamic_binaries/Test_Both/0a0c98cc7a2dc1fc27a977e7cd507504f9999921a53d4f5b78f638738826c978'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/Test_Both'

# path = '/home/mohit/Desktop/Dynamic_binaries/Benign_Some/0bc8af546901e6c20611c5250bd65acd0c4a8613bd8f8835f0d4680b5777f051'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/Benign_Some'

# path = '/home/mohit/Desktop/Dynamic_binaries/Malicious_Some/0a143c2e6dabb31a31a6db8cb7a0f77558ae44a38687d5f831c87a98054f0ef9'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/Malicious_Some'

# path = '/home/mohit/Desktop/Dynamic_binaries/test_random/baby_steps.exe'
# path2 = '/home/mohit/Desktop/Dynamic_binaries/test_random'

# pe = pefile.PE(path)
# print(pe)
# files = glob.glob(path2)

# for name in files:
list_of_files = (os.listdir(path2))
    
print(len(list_of_files))

##########################################################################################
# #                           Removing duplicates

temp_list_of_files = []
temp_list_of_files = list_of_files[:]
temp_hashes = []
for file in temp_list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
#         temp_list_of_files.append(file)
    else:
        list_of_files.remove(file)
        
print(len(list_of_files))

###############################################################333########################


list_train = []
# getting the files to test

for f in list_of_files:
    temp_dict = {}
    attr_dict = temp_dict
    try:
        pe = pefile.PE(path2+'/'+f)
    except Exception as e:
        print("")
    DOS_HEADER()
#   print('after DOS', attr_dict)
    FILE_HEADER()
    OPTIONAL_HEADER()
    temp_dict = attr_dict.copy()
    list_train.append(temp_dict)

df_training = pd.DataFrame(list_train)
# print(df_training)
# df_training.pop('Classifier')
X_new = df_training
X_new = X_new.fillna(0) 
# # print(X_new)

# Decision Tree
from sklearn import tree
d_clf = tree.DecisionTreeClassifier()
d_clf = d_clf.fit(X, y)
print(d_clf.predict(X_new))
print(len(d_clf.predict(X_new)))
print(d_clf.score(X,y))


# In[ ]:





# In[18]:


# Decision Tree
from sklearn import tree
d_clf = tree.DecisionTreeClassifier()
d_clf = d_clf.fit(X, y)
print(d_clf.predict(X_new))
print(len(d_clf.predict(X_new)))
print(d_clf.score(X,y))

