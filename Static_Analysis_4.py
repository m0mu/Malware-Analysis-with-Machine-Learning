
# coding: utf-8

# In[2]:

import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = 'C:/Users/momo/Desktop/benign/0cd2d23daea0baff1d553982269460d09864a3eb68c9e93339a11978a877498f'
path2 = 'C:/Users/momo/Desktop/benign'

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")
        
# getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
print('BENIGN: \n',list_of_benign_dict)


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = 'C:/Users/momo/Desktop/malicious/00abdfceae9084ff5ef1a8215f120b2b55db104d50ef738e01d6f99423a08def'
path4 = 'C:/Users/momo/Desktop/malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
print('\n MALICIOUS: \n', list_of_malicious_dict)

##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)
# print(df)
# print(df2)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print(to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
print(final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
import matplotlib.pyplot as plt


for l in final_list:
    plt.figure()
    df4 = pd.DataFrame(l)
    plt.title('HAHAHA it works!')
    df4.boxplot()
    plt.show()


# In[40]:

import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = 'C:/Users/momo/Desktop/benign/0cd2d23daea0baff1d553982269460d09864a3eb68c9e93339a11978a877498f'
path2 = 'C:/Users/momo/Desktop/benign'

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")

    
import hashlib
import sys

def sha256_checksum(filename, path, block_size=65536):
    filename = str(path)+str('/'+filename)
    sha256 = hashlib.sha256()
    with open(filename, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()


        
# getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    
##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
# print('BENIGN: \n',list_of_benign_dict)


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = 'C:/Users/momo/Desktop/malicious/00abdfceae9084ff5ef1a8215f120b2b55db104d50ef738e01d6f99423a08def'
path4 = 'C:/Users/momo/Desktop/malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))

##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path4)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
# print('\n MALICIOUS: \n', list_of_malicious_dict)


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print(to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print(final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
# import matplotlib.pyplot as plt


# for l in final_list:
#     plt.figure()
#     df4 = pd.DataFrame(l)
#     plt.title('HAHAHA it works!')
#     df4.boxplot()
#     plt.show()

################################################################
#                       Training Model
X = big_data
y = target


from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 3)


knn.fit(X[1:],y[1:])

X_new = X[:1]

print(knn.predict(X_new))



# In[ ]:




# In[12]:

import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = 'C:/Users/momo/Desktop/benign/0cd2d23daea0baff1d553982269460d09864a3eb68c9e93339a11978a877498f'
path2 = 'C:/Users/momo/Desktop/benign'

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")

    
import hashlib
import sys

def sha256_checksum(filename, path, block_size=65536):
    filename = str(path)+str('/'+filename)
    sha256 = hashlib.sha256()
    with open(filename, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()


        
# getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    
##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
# print('BENIGN: \n',list_of_benign_dict)


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = 'C:/Users/momo/Desktop/malicious/00abdfceae9084ff5ef1a8215f120b2b55db104d50ef738e01d6f99423a08def'
path4 = 'C:/Users/momo/Desktop/malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))

##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path4)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
# print('\n MALICIOUS: \n', list_of_malicious_dict)


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print(to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print(final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
# import matplotlib.pyplot as plt


# for l in final_list:
#     plt.figure()
#     df4 = pd.DataFrame(l)
#     plt.title('HAHAHA it works!')
#     df4.boxplot()
#     plt.show()

################################################################
#                       Training Model
X = big_data
y = target

# getting the names of the files
path = 'C:/Users/momo/Desktop/Test_Benign/0ff6cdba44516cddf09411e767c599291cfe0ab9268be8e5f452845fad85226c'
path2 = 'C:/Users/momo/Desktop/Test_Benign'
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    

list_train = []
# getting the benign files to test
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()

    temp_dict = attr_dict.copy()
    list_train.append(temp_dict)

df_training = pd.DataFrame(list_train)
df_training.pop('Classifier')
X_new = df_training
# print(X_new)



from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(X, y)

print(knn.predict(X_new))



# In[ ]:




# In[4]:

# Cross Validation and Parameter tunning
import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = 'C:/Users/momo/Desktop/benign/0cd2d23daea0baff1d553982269460d09864a3eb68c9e93339a11978a877498f'
path2 = 'C:/Users/momo/Desktop/benign'

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")

    
import hashlib
import sys

def sha256_checksum(filename, path, block_size=65536):
    filename = str(path)+str('/'+filename)
    sha256 = hashlib.sha256()
    with open(filename, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()


        
# getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    
##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
# print('BENIGN: \n',list_of_benign_dict)


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = 'C:/Users/momo/Desktop/malicious/00abdfceae9084ff5ef1a8215f120b2b55db104d50ef738e01d6f99423a08def'
path4 = 'C:/Users/momo/Desktop/malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))

##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path4)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
# print('\n MALICIOUS: \n', list_of_malicious_dict)


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print(to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print(final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
# import matplotlib.pyplot as plt


# for l in final_list:
#     plt.figure()
#     df4 = pd.DataFrame(l)
#     plt.title('HAHAHA it works!')
#     df4.boxplot()
#     plt.show()

################################################################
#                       Training Model
X = big_data
y = target

# Benign
# path = 'C:/Users/momo/Desktop/Test_Benign/0ff6cdba44516cddf09411e767c599291cfe0ab9268be8e5f452845fad85226c'
# path2 = 'C:/Users/momo/Desktop/Test_Benign'
# #Malicious
# path = 'C:/Users/momo/Desktop/Test_Malicious/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
# path2 = 'C:/Users/momo/Desktop/Test_Malicious'
# Test Both
path = 'C:/Users/momo/Desktop/Test_Both/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
path2 = 'C:/Users/momo/Desktop/Test_Both'


pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    

list_train = []
# getting the benign files to test
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()

    temp_dict = attr_dict.copy()
    list_train.append(temp_dict)

df_training = pd.DataFrame(list_train)
df_training.pop('Classifier')
X_new = df_training
# # print(X_new)

# # Cross Validation and Parameter tuning
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cross_validation import cross_val_score
knn = KNeighborsClassifier(n_neighbors = 10)
# scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')
# print(scores)
# print(scores.mean())

# # Tunning parameters
# # k_range = range(1, 20)
# # k_scores = []
# # for k in k_range:
# #     knn = KNeighborsClassifier(n_neighbors = k)
# #     scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')
# #     (k_scores.append(scores.mean()))
# # print(k_scores)
# knn.fit(X, y)
# print(knn.predict(X_new))

# # # PLOTTING FOR BETTER VISUALS
# # %matplotlib inline
# # #plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)
# # plt.plot(k_range, k_scores)
# # plt.xlabel('Value of K for KNN')
# # plt.ylabel('Cross-validated Accuracy')

from sklearn.grid_search import GridSearchCV
k_range = (1, 20)

param_grid = dict(n_neighbors=k_range)
grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')

grid.fit(X, y)

# create a list of mean scores
grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]
print(grid_mean_scores)

#plot the results
plt.plot(k_range, grid_mean_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Cross-Validated Accuracy')

print(grid.best_score_)
print(grid.best_params_)
print(grid.best_estimator_)


# In[ ]:

#################################################################################################################################


# In[2]:

# Cross Validation and Parameter tunning
import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = 'C:/Users/momo/Desktop/benign/0cd2d23daea0baff1d553982269460d09864a3eb68c9e93339a11978a877498f'
path2 = 'C:/Users/momo/Desktop/benign'

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")

    
import hashlib
import sys

def sha256_checksum(filename, path, block_size=65536):
    filename = str(path)+str('/'+filename)
    sha256 = hashlib.sha256()
    with open(filename, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()


        
# getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    
##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
# print('BENIGN: \n',list_of_benign_dict)


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = 'C:/Users/momo/Desktop/malicious/00abdfceae9084ff5ef1a8215f120b2b55db104d50ef738e01d6f99423a08def'
path4 = 'C:/Users/momo/Desktop/malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))

##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path4)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
# print('\n MALICIOUS: \n', list_of_malicious_dict)


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print(to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print(final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
# import matplotlib.pyplot as plt


# for l in final_list:
#     plt.figure()
#     df4 = pd.DataFrame(l)
#     plt.title('HAHAHA it works!')
#     df4.boxplot()
#     plt.show()

################################################################
#                       Training Model
X = big_data
y = target

# Benign
# path = 'C:/Users/momo/Desktop/Test_Benign/0ff6cdba44516cddf09411e767c599291cfe0ab9268be8e5f452845fad85226c'
# path2 = 'C:/Users/momo/Desktop/Test_Benign'
# #Malicious
# path = 'C:/Users/momo/Desktop/Test_Malicious/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
# path2 = 'C:/Users/momo/Desktop/Test_Malicious'
# Test Both
path = 'C:/Users/momo/Desktop/Test_Both/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
path2 = 'C:/Users/momo/Desktop/Test_Both'


pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    

list_train = []
# getting the benign files to test
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()

    temp_dict = attr_dict.copy()
    list_train.append(temp_dict)

df_training = pd.DataFrame(list_train)
df_training.pop('Classifier')
X_new = df_training
# # print(X_new)

# # Cross Validation and Parameter tuning
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cross_validation import cross_val_score
knn = KNeighborsClassifier(n_neighbors = 10)
scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')
print(scores)
print(scores.mean())

# Tunning parameters
k_range = range(1, 20)
k_scores = []
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors = k)
    scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')
    (k_scores.append(scores.mean()))
print(k_scores)
knn.fit(X, y)
print(knn.predict(X_new))

# PLOTTING FOR BETTER VISUALS
get_ipython().magic('matplotlib inline')
#plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(k_range, k_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Cross-validated Accuracy')



################################################# GRID SEARCH ########################################################3
# from sklearn.grid_search import GridSearchCV
# k_range = (1, 20)

# param_grid = dict(n_neighbors=k_range)
# grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')

# grid.fit(X, y)

# # create a list of mean scores
# grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]
# print(grid_mean_scores)

# #plot the results
# plt.plot(k_range, grid_mean_scores)
# plt.xlabel('Value of K for KNN')
# plt.ylabel('Cross-Validated Accuracy')

# print(grid.best_score_)
# print(grid.best_params_)
# print(grid.best_estimator_)


# In[ ]:

################################################## USING RANDOMIZED SEARCH #####################################################


# In[3]:

# Cross Validation and Parameter tunning
import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = 'C:/Users/momo/Desktop/benign/0cd2d23daea0baff1d553982269460d09864a3eb68c9e93339a11978a877498f'
path2 = 'C:/Users/momo/Desktop/benign'

def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")

    
import hashlib
import sys

def sha256_checksum(filename, path, block_size=65536):
    filename = str(path)+str('/'+filename)
    sha256 = hashlib.sha256()
    with open(filename, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()


        
# getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    
##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path2)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
# print('BENIGN: \n',list_of_benign_dict)


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = 'C:/Users/momo/Desktop/malicious/00abdfceae9084ff5ef1a8215f120b2b55db104d50ef738e01d6f99423a08def'
path4 = 'C:/Users/momo/Desktop/malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))

##########################################################################################
#                           Removing duplicates

temp_list_of_files = []
temp_hashes = []
for file in list_of_files:
    h = sha256_checksum(file, path4)
    if h not in temp_hashes:
        temp_hashes.append(h)
        temp_list_of_files.append(file)

list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
# print('\n MALICIOUS: \n', list_of_malicious_dict)


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
# print(to_plot)

# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
# print(to_plot_malicious)

# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print(final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
# import matplotlib.pyplot as plt


# for l in final_list:
#     plt.figure()
#     df4 = pd.DataFrame(l)
#     plt.title('HAHAHA it works!')
#     df4.boxplot()
#     plt.show()

################################################################
#                       Training Model
X = big_data
y = target

# Benign
# path = 'C:/Users/momo/Desktop/Test_Benign/0ff6cdba44516cddf09411e767c599291cfe0ab9268be8e5f452845fad85226c'
# path2 = 'C:/Users/momo/Desktop/Test_Benign'
# #Malicious
# path = 'C:/Users/momo/Desktop/Test_Malicious/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
# path2 = 'C:/Users/momo/Desktop/Test_Malicious'
# Test Both
path = 'C:/Users/momo/Desktop/Test_Both/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
path2 = 'C:/Users/momo/Desktop/Test_Both'


pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    

list_train = []
# getting the benign files to test
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()

    temp_dict = attr_dict.copy()
    list_train.append(temp_dict)

df_training = pd.DataFrame(list_train)
df_training.pop('Classifier')
X_new = df_training
# # print(X_new)

#################################################Cross Validation and Parameter tuning
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cross_validation import cross_val_score
knn = KNeighborsClassifier(n_neighbors = 10)
# scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')
# print(scores)
# print(scores.mean())

# # Tunning parameters
# k_range = range(1, 20)
# k_scores = []
# for k in k_range:
#     knn = KNeighborsClassifier(n_neighbors = k)
#     scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')
#     (k_scores.append(scores.mean()))
# print(k_scores)
# knn.fit(X, y)
# print(knn.predict(X_new))

# # PLOTTING FOR BETTER VISUALS
# %matplotlib inline
# #plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)
# plt.plot(k_range, k_scores)
# plt.xlabel('Value of K for KNN')
# plt.ylabel('Cross-validated Accuracy')



################################################# GRID SEARCH ########################################################3
# from sklearn.grid_search import GridSearchCV
# k_range = (1, 20)

# param_grid = dict(n_neighbors=k_range)
# grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')

# grid.fit(X, y)

# # create a list of mean scores
# grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]
# print(grid_mean_scores)

# #plot the results
# plt.plot(k_range, grid_mean_scores)
# plt.xlabel('Value of K for KNN')
# plt.ylabel('Cross-Validated Accuracy')

# print(grid.best_score_)
# print(grid.best_params_)
# print(grid.best_estimator_)

################################################  RANDOMIZED  SEARCH #########################################################

from sklearn.grid_search import RandomizedSearchCV

k_range = range(1, 20)
weight_options = ['uniform', 'distance']

param_dist = dict(n_neighbors = k_range, weights = weight_options)

rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)
rand.fit(X, y)
rand.grid_scores_

# examine the best model
print(rand.best_score_)
print(rand.best_params_)

# run RandomizedSearchCV 20 times (with n_iter = 10) and record the best score
# best_scores = []
# for _ in range(20):
#     rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10)
#     rand.fit(X, y)
#     best_scores.append(round(rand.best_score_, 3))
# print(best_scores)


# In[ ]:




# In[ ]:



