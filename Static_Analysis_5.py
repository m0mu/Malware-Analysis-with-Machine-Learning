
# coding: utf-8

# In[51]:


import pefile
from collections import OrderedDict
import glob, sys, os
import matplotlib as mp
import matplotlib.pyplot as plt
import pandas as pd

list_of_benign_dict = []
list_of_malicious_dict = []
attr_dict = {}
list_of_files = ""

path = '/home/mohit/Desktop/Dynamic_binaries/Benign/0bc8af546901e6c20611c5250bd65acd0c4a8613bd8f8835f0d4680b5777f051'
path2 = '/home/mohit/Desktop/Dynamic_binaries/Benign'


def DOS_HEADER():
    global attr_dict
    try:
        attr_dict["e_magic"] = pe.DOS_HEADER.e_magic
        attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
        attr_dict["e_cp"] = pe.DOS_HEADER.e_cp
        attr_dict["e_crlc"] = pe.DOS_HEADER.e_crlc
        attr_dict["e_cparhdr"] = pe.DOS_HEADER.e_cparhdr
        attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc
        attr_dict["e_maxalloc"] = pe.DOS_HEADER.e_maxalloc
        attr_dict["e_ss"] = pe.DOS_HEADER.e_ss
        attr_dict["e_sp"] = pe.DOS_HEADER.e_sp
        attr_dict["e_csum"] = pe.DOS_HEADER.e_csum
        attr_dict["e_ip"] = pe.DOS_HEADER.e_ip
        attr_dict["e_cs"] = pe.DOS_HEADER.e_cs
        attr_dict["e_lfarlc"] = pe.DOS_HEADER.e_lfarlc
        attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
#         attr_dict["e_res"] = int.from_bytes(pe.DOS_HEADER.e_res,byteorder='big')
        attr_dict["e_oemid"] = pe.DOS_HEADER.e_oemid
        attr_dict["e_oeminfo"] = pe.DOS_HEADER.e_oeminfo
#         attr_dict["e_res2"] = int.from_bytes(pe.DOS_HEADER.e_res2,byteorder='big')
        attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
    except Exception as e:
        print("")

def FILE_HEADER():
    global attr_dict
    try:
        attr_dict["Machine"] = pe.FILE_HEADER.Machine
        attr_dict["NumberOfSections"] = pe.FILE_HEADER.NumberOfSections
#         attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
        attr_dict["PointerToSymbolTable"] = pe.FILE_HEADER.PointerToSymbolTable
        attr_dict["NumberOfSymbols"] = pe.FILE_HEADER.NumberOfSymbols
        attr_dict["SizeOfOptionalHeader"] = pe.FILE_HEADER.SizeOfOptionalHeader
        attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
    except Exception as e:
        print("")

def OPTIONAL_HEADER():
    global attr_dict
    try:
        attr_dict["Magic"] = pe.OPTIONAL_HEADER.Magic
        attr_dict["MajorLinkerVersion"] = pe.OPTIONAL_HEADER.MajorLinkerVersion
        attr_dict["MinorLinkerVersion"] = pe.OPTIONAL_HEADER.MinorLinkerVersion
        attr_dict["SizeOfCode"] = pe.OPTIONAL_HEADER.SizeOfCode
        attr_dict["SizeOfInitializedData"] = pe.OPTIONAL_HEADER.SizeOfInitializedData
        attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
        attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
        attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
        attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
        attr_dict["ImageBase"] = pe.OPTIONAL_HEADER.ImageBase
        attr_dict["SectionAlignment"] = pe.OPTIONAL_HEADER.SectionAlignment
        attr_dict["FileAlignment"] = pe.OPTIONAL_HEADER.FileAlignment
        attr_dict["MajorOperatingSystemVersion"] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
        attr_dict["MinorOperatingSystemVersion"] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion
        attr_dict["MajorImageVersion"] = pe.OPTIONAL_HEADER.MajorImageVersion
        attr_dict["MinorImageVersion"] = pe.OPTIONAL_HEADER.MinorImageVersion
        attr_dict["MajorSubsystemVerison"] = pe.OPTIONAL_HEADER.MajorSubsystemVersion
        attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
        attr_dict["Reserved1"] = pe.OPTIONAL_HEADER.Reserved1
        attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
        attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
        attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum
        attr_dict["Subsystem"] = pe.OPTIONAL_HEADER.Subsystem
        attr_dict["DllCharacteristics"] = pe.OPTIONAL_HEADER.DllCharacteristics
        attr_dict["SizeOfStackReserve"] = pe.OPTIONAL_HEADER.SizeOfStackReserve
        attr_dict["SizeOfStackCommit"] = pe.OPTIONAL_HEADER.SizeOfStackCommit
        attr_dict["SizeOfHeapReserve"] = pe.OPTIONAL_HEADER.SizeOfHeapReserve
        attr_dict["SizeOfHeapCommit"] = pe.OPTIONAL_HEADER.SizeOfHeapCommit
        attr_dict["LoaderFlags"] = pe.OPTIONAL_HEADER.LoaderFlags
        attr_dict["NumberOfRvaAndSizes"] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes
    except Exception as e:
        print("")

# def DOS_HEADER():
#     global attr_dict
#     try:
#         attr_dict["e_cblp"] = pe.DOS_HEADER.e_cblp
#         attr_dict["e_cp"] = pe.DOS_HEADER.e_cp        
#         attr_dict["e_minialloc"] = pe.DOS_HEADER.e_minalloc        
#         attr_dict["e_ovno"] = pe.DOS_HEADER.e_ovno
#         attr_dict["e_lfanew"] = pe.DOS_HEADER.e_lfanew
    
#     except Exception as e:
#         print("")

# def FILE_HEADER():
#     global attr_dict
#     try:
#         attr_dict["TimeDateStamp"] = pe.FILE_HEADER.TimeDateStamp
#         attr_dict["Characteristics"] = pe.FILE_HEADER.Characteristics
        
#     except Exception as e:
#         print("")

# def OPTIONAL_HEADER():
#     global attr_dict
#     try:
#         attr_dict["SizeOfUninitializedData"] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
#         attr_dict["AddressOfEntryPoint"] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
#         attr_dict["BaseOfCode"] = pe.OPTIONAL_HEADER.BaseOfCode
#         attr_dict["BaseOfData"] = pe.OPTIONAL_HEADER.BaseOfData
#         attr_dict["MinorSubsystemVersion"] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
#         attr_dict["SizeOfImage"] = pe.OPTIONAL_HEADER.SizeOfImage
#         attr_dict["SizeOfHeaders"] = pe.OPTIONAL_HEADER.SizeOfHeaders
#         attr_dict["CheckSum"] = pe.OPTIONAL_HEADER.CheckSum

    except Exception as e:
        print("")

    
# import hashlib
# import sys

# def sha256_checksum(filename, path, block_size=65536):
#     filename = str(path)+str('/'+filename)
#     sha256 = hashlib.sha256()
#     with open(filename, 'rb') as f:
#         for block in iter(lambda: f.read(block_size), b''):
#             sha256.update(block)
#     return sha256.hexdigest()


# In[ ]:


#2  BENIGN FILES


# In[54]:


#  getting the names of the files
pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    
########################################################################################
# #                           Removing duplicates

# temp_list_of_files = []
# temp_hashes = []
# for file in list_of_files:
#     h = sha256_checksum(file, path2)
#     if h not in temp_hashes:
#         temp_hashes.append(h)
#         temp_list_of_files.append(file)

# list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 0
    temp_dict = attr_dict.copy()
    list_of_benign_dict.append(temp_dict)
print('BENIGN: \n',list_of_benign_dict)



# In[ ]:


#3 Malicious Files


# In[52]:


#################################################################
#               Getting list of dict For Malicious File
# ===============================================================

path3 = '/home/mohit/Desktop/Dynamic_binaries/Malicious/0a143c2e6dabb31a31a6db8cb7a0f77558ae44a38687d5f831c87a98054f0ef9'
path4 = '/home/mohit/Desktop/Dynamic_binaries/Malicious'

# getting the names of the files
pe = pefile.PE(path3)
files = glob.glob(path4)
for name in files:
    list_of_files = (os.listdir(name))

##########################################################################################
# #                           Removing duplicates

# temp_list_of_files = []
# temp_hashes = []
# for file in list_of_files:
#     h = sha256_checksum(file, path4)
#     if h not in temp_hashes:
#         temp_hashes.append(h)
#         temp_list_of_files.append(file)

# list_of_files = temp_list_of_files[:]

############################################################################################
    

# appending names to get the full path to files

# getting the list_of_dict_of_benign_files
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path4, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()
#         print(attr_dict)
    attr_dict["Classifier"] = 1
    temp_dict = attr_dict.copy()
    list_of_malicious_dict.append(temp_dict)
print('\n MALICIOUS: \n', list_of_malicious_dict)




# In[ ]:


#3


# In[53]:


import operator
for i in list_of_malicious_dict:
    print(max(i.values()), max(i, key=lambda key: i[key]))


# In[ ]:





# In[56]:


##########################################################################################
#                                       Plotting

df = pd.DataFrame(list_of_benign_dict)
df2 = pd.DataFrame(list_of_malicious_dict)

# merging both dataframes
big_data = df.append(df2, ignore_index=True)

# getting the target column out of dataframe
target = big_data['Classifier']
big_data.pop('Classifier')
# print(target)
# print(big_data)

get_ipython().magic('matplotlib inline')

# getting the list of keys
list_of_keys = []
for dic in list_of_benign_dict:
    for key in dic.keys():
        list_of_keys.append(key)
list_of_keys = set(list_of_keys)
# print(list_of_keys)

# getting each feature from benign in a different list
to_plot = []
for key in list_of_keys:
    temp_list =[]
    for dic in list_of_benign_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_benign')] = dic[key]
            temp_list.append(new_dic)
    to_plot.append(temp_list)
print(to_plot)


# In[ ]:





# In[57]:


# getting each feature from malicious in the same dict
to_plot_malicious = []
for key in list_of_keys:
    temp_list = []
    for dic in list_of_malicious_dict:
        if key in dic:
            new_dic = {}
            new_dic[key+str('_malicious')] = dic[key]
            temp_list.append(new_dic)
    to_plot_malicious.append(temp_list)
print('\n \n', to_plot_malicious)



# In[ ]:





# In[59]:


# merging both list of list of dict
from itertools import cycle
final_list = []
for a, b in zip(to_plot, to_plot_malicious):
    temp_list = []
    for d1, d2 in zip(a, b):
        d1.update(d2)
        temp_list.append(d1)
    final_list.append(temp_list)
# print('\n \n \n \n \n \n \n \n', final_list)

################################################################
#                 Trying to Plot each feature
# ==============================================================
import matplotlib.pyplot as plt

for l in final_list:
    plt.figure()
    df4 = pd.DataFrame(l)
    plt.title('HAHAHA it works!')
    df4.boxplot()
    plt.show()


# In[ ]:


#4


# In[60]:



################################################################
#                       Training Model
X = big_data
y = target

# Benign
# path = 'C:/Users/momo/Desktop/Test_Benign/0ff6cdba44516cddf09411e767c599291cfe0ab9268be8e5f452845fad85226c'
# path2 = 'C:/Users/momo/Desktop/Test_Benign'
# #Malicious
# path = 'C:/Users/momo/Desktop/Test_Malicious/000b7774e51d0a788917b6966fae175ddfd5e2051021fbf89a2380bad14793fd'
# path2 = 'C:/Users/momo/Desktop/Test_Malicious'
# Test Both
path = '/home/mohit/Desktop/Dynamic_binaries/Test_Both/0a0c98cc7a2dc1fc27a977e7cd507504f9999921a53d4f5b78f638738826c978'
path2 = '/home/mohit/Desktop/Dynamic_binaries/Test_Both'


pe = pefile.PE(path)
files = glob.glob(path2)
for name in files:
    list_of_files = (os.listdir(name))
    

list_train = []
# getting the benign files to test
for f in list_of_files:
    temp_dict = {}
    for file in glob.glob(os.path.join(path2, f)):
        try:
            pe = pefile.PE(file)
        except Exception as e:
            print("")
        DOS_HEADER()
        FILE_HEADER()
        OPTIONAL_HEADER()

    temp_dict = attr_dict.copy()
    list_train.append(temp_dict)

df_training = pd.DataFrame(list_train)
df_training.pop('Classifier')
X_new = df_training
# # print(X_new)




# In[61]:


#################################################Cross Validation and Parameter tuning
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cross_validation import cross_val_score
knn = KNeighborsClassifier(n_neighbors = 10)
# scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')
# print(scores)
# print(scores.mean())

# # Tunning parameters
# k_range = range(1, 20)
# k_scores = []
# for k in k_range:
#     knn = KNeighborsClassifier(n_neighbors = k)
#     scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')
#     (k_scores.append(scores.mean()))
# print(k_scores)
# knn.fit(X, y)
# print(knn.predict(X_new))

# # PLOTTING FOR BETTER VISUALS
# %matplotlib inline
# #plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)
# plt.plot(k_range, k_scores)
# plt.xlabel('Value of K for KNN')
# plt.ylabel('Cross-validated Accuracy')



# In[ ]:





# In[62]:


################################################# GRID SEARCH ########################################################3
# from sklearn.grid_search import GridSearchCV
# k_range = (1, 20)

# param_grid = dict(n_neighbors=k_range)
# grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')

# grid.fit(X, y)

# # create a list of mean scores
# grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]
# print(grid_mean_scores)

# #plot the results
# plt.plot(k_range, grid_mean_scores)
# plt.xlabel('Value of K for KNN')
# plt.ylabel('Cross-Validated Accuracy')

# print(grid.best_score_)
# print(grid.best_params_)
# print(grid.best_estimator_)


# In[ ]:





# In[63]:


################################################  RANDOMIZED  SEARCH #########################################################

from sklearn.grid_search import RandomizedSearchCV

k_range = range(1, 20)
weight_options = ['uniform', 'distance']

param_dist = dict(n_neighbors = k_range, weights = weight_options)

rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)
rand.fit(X, y)
rand.grid_scores_

# examine the best model
print(rand.best_score_)
print(rand.best_params_)

# run RandomizedSearchCV 20 times (with n_iter = 10) and record the best score
best_scores = []
for _ in range(20):
    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10)
    rand.fit(X, y)
    best_scores.append(round(rand.best_score_, 3))
print(best_scores)

